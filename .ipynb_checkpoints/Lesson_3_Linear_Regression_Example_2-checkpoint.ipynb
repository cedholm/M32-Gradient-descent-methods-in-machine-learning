{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40aaf12a",
   "metadata": {
    "id": "40aaf12a"
   },
   "source": [
    "# Gradient Descent with Linear Regression -  Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ca7a1",
   "metadata": {
    "id": "8c1ca7a1"
   },
   "source": [
    "## Predicting the height of young children using their age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343eb87",
   "metadata": {
    "id": "2343eb87"
   },
   "source": [
    "Suppose we want to predict a child's height (centimeters) from their age (years).  We have data giving measurements of heights for various children between the ages of two and eight. The $y$-values are the heights measured in centimeters, and the $x$-values are the ages of the children corresponding to the heights.\n",
    "\n",
    "Each height and age tuple constitutes one training sample  $(x^{(i)}, y^{(i)})$ in our dataset. There are $N = 114$ training samples, and we will use them to develop a linear regression model.  Since our age data is one-dimensional, the objective function (here, mean squared error (MSE)), $D_{MSE}$ is\n",
    "\n",
    "$$\\begin{align}\n",
    "D_{MSE}(\\theta_0, \\theta_1) &= \\frac{1}{N}||\\theta_1 x + \\theta_0 - y||^2\\\\\n",
    " &= \\frac{1}{N}\\sum_{k=1}^N (\\theta_1 x^k + \\theta_0 - y^k)^2.\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "The gradient of $D_{MSE}$ is\n",
    "\n",
    "$$\\nabla D_{MSE} (\\theta_0, \\theta_1) =\n",
    "\\frac{1}{N}\\Big(2\\sum_{k=1}^N({\\theta_1 x^k + \\theta_0 - y^k),2\\sum_{k=1}^N x^k(\\theta_1 x^k + \\theta_0 - y^k)}\\Big).\n",
    "$$\n",
    "\n",
    "First, let us take a look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df74f57f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1696391594035,
     "user": {
      "displayName": "Christina Edholm",
      "userId": "06638694382813985364"
     },
     "user_tz": 420
    },
    "id": "df74f57f",
    "outputId": "bd86b9f3-c2c8-45ba-9ab6-a6df73935587"
   },
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Import package\n",
    "#------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Plot style\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "#------------------------\n",
    "# Make dataframe\n",
    "#------------------------\n",
    "\n",
    "# Creates a dataframe from file called Height-Weight-Data.csv\n",
    "url = 'https://raw.githubusercontent.com/cedholm/M32-Gradient-descent-methods-in-machine-learning/main/Height-Weight-Data.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Prints first 5 lines of data\n",
    "print(df.head(5))\n",
    "\n",
    "# Print basic stats on data\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6cd9fe",
   "metadata": {
    "id": "1f6cd9fe"
   },
   "source": [
    "We want to look at the relationship between age and height."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a78f78",
   "metadata": {
    "id": "d5a78f78"
   },
   "source": [
    "###  Part 1\n",
    "\n",
    "Implement the gradient descent algorithm using a learning rate of $\\gamma = 0.01$ with the code below.\n",
    "\n",
    "Initialize the parameters to $\\boldsymbol{\\theta} = \\mathbf{0}$, and run one iteration of gradient descent from this initial starting point. Record the value of of $\\theta_0$ and $\\theta_1$ that you get after this first iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dfe89a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1696391637809,
     "user": {
      "displayName": "Christina Edholm",
      "userId": "06638694382813985364"
     },
     "user_tz": 420
    },
    "id": "a4dfe89a",
    "outputId": "a7024b8a-856a-493b-fa0c-357b8798a24e"
   },
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Create functions\n",
    "#------------------------\n",
    "\n",
    "# Create the function we want to minimumize\n",
    "# Here, we have f = D(theta0, theta1) = \\sum_{k=1}^N (\\theta_1 x^k + \\theta_0 - y^k)^2\n",
    "def f(x,y, Theta):\n",
    "    theta0, theta1 = Theta\n",
    "    f = sum((theta1*x + theta0 - y)**2)\n",
    "    return f\n",
    "\n",
    "# Create the gradient vector\n",
    "# Here, we have \\nabla D = 2\\sum_{k=1}^N (\\theta_1 x_k + \\theta_0 - y_k)*<1, x_k>\n",
    "def gradf(x,y, Theta):\n",
    "    # divide up thetas\n",
    "    theta0, theta1 = Theta\n",
    "    N = len(x)\n",
    "    # find derivatives w.r.t each theta\n",
    "    deriv_theta0 = 2/N*sum(theta1*x + theta0 - y)\n",
    "    deriv_theta1 = 2/N*sum(x*(theta1*x + theta0 - y))\n",
    "    # put in vector form\n",
    "    gradient = np.array([deriv_theta0, deriv_theta1])\n",
    "    return gradient\n",
    "\n",
    "#------------------------\n",
    "# Create variables\n",
    "#------------------------\n",
    "\n",
    "# Data to import into functions\n",
    "x = df['age'].values\n",
    "y = df['height'].values\n",
    "\n",
    "# Starting point\n",
    "theta0 = 0\n",
    "theta1 = 0\n",
    "\n",
    "# Step size to move along gradient\n",
    "gamma = 0.01\n",
    "\n",
    "# Starting values of theta vector\n",
    "initialTheta = np.array([theta0,theta1])\n",
    "\n",
    "# initialize num of steps to take\n",
    "totalNumSteps = 0\n",
    "# create a max number of steps to take\n",
    "maxSteps = 1\n",
    "# how close we want to be to f\n",
    "tolerance = 0.000001\n",
    "# initial difference between old and new theta values\n",
    "diff = 100\n",
    "\n",
    "# initial theta values to starting point\n",
    "currentTheta = initialTheta\n",
    "\n",
    "# initialize value of objective function\n",
    "currentfValues = f(x, y, initialTheta)\n",
    "\n",
    "#------------------------\n",
    "# Initialize lists\n",
    "#------------------------\n",
    "\n",
    "# creates list of all theta pairs\n",
    "thetaValuesList = [currentTheta]\n",
    "# creates list of all distance function values\n",
    "fValuesList = [currentfValues]\n",
    "# creates list of the norm between old and new theta values\n",
    "diffList = [diff]\n",
    "\n",
    "#------------------------\n",
    "# Gradient descent calcs\n",
    "#------------------------\n",
    "\n",
    "while((totalNumSteps < maxSteps)&(diff > tolerance)):\n",
    "\n",
    "    # Calculate new theta values - move along gradient to new theta position\n",
    "    updatedTheta = currentTheta - gamma*gradf(x, y, currentTheta)\n",
    "\n",
    "    # Calculate new function values with new theta values\n",
    "    updatedfValues = f(x,y, updatedTheta)\n",
    "\n",
    "    # Calculate the difference between current and new theta values\n",
    "    #diff = norm(updatedTheta-currentTheta,2)\n",
    "    diffList.append(diff)\n",
    "\n",
    "    # Add 1 to counter for total number of steps\n",
    "    totalNumSteps += 1\n",
    "\n",
    "    # Add to list of theta values\n",
    "    thetaValuesList.append(updatedTheta)\n",
    "    # Add to list of f function values\n",
    "    fValuesList.append(updatedfValues)\n",
    "\n",
    "    # Reassign current theta vector to new theta vector\n",
    "    currentTheta = updatedTheta\n",
    "    # Reassign current f values to new f values\n",
    "    currentfValues = updatedfValues\n",
    "\n",
    "print('Our theta_0 value after', totalNumSteps, 'timestep is', thetaValuesList[-1][0])\n",
    "print('Our theta_1 value after', totalNumSteps, 'timestep is',  thetaValuesList[-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca20a2",
   "metadata": {
    "id": "c1ca20a2"
   },
   "source": [
    "Did you get $\\theta_0 = 1.8285$ and $\\theta_1 = 7.8286$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a577f1b6",
   "metadata": {
    "id": "a577f1b6"
   },
   "source": [
    "### Part 2\n",
    "\n",
    "Continue running gradient descent for more iterations until $\\theta$ converges. This will take a total of about 4000 iterations. After convergence, record the final values of $\\theta_0$ and $\\theta_1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa05125",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 825,
     "status": "ok",
     "timestamp": 1696391650514,
     "user": {
      "displayName": "Christina Edholm",
      "userId": "06638694382813985364"
     },
     "user_tz": 420
    },
    "id": "1fa05125",
    "outputId": "e2e74aa8-def0-4d15-e6a0-d95ffc09a270"
   },
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Create functions\n",
    "#------------------------\n",
    "\n",
    "# Create the function we want to minimumize\n",
    "#------------------------\n",
    "# Here, we have f = D(theta0, theta1) = \\sum_{k=1}^N (\\theta_1 x^k + \\theta_0 - y^k)^2\n",
    "\n",
    "def f(x,y, Theta):\n",
    "    theta0, theta1 = Theta\n",
    "    f = sum((theta1*x + theta0 - y)**2)\n",
    "    return f\n",
    "\n",
    "# Create the gradient vector\n",
    "#------------------------\n",
    "# Here, we have \\nabla D = 2\\sum_{k=1}^N (\\theta_1 x_k + \\theta_0 - y_k)*<1, x_k>\n",
    "\n",
    "def gradf(x,y, Theta):\n",
    "    # divide up thetas\n",
    "    theta0, theta1 = Theta\n",
    "    N = len(x)\n",
    "    # find derivatives w.r.t each theta\n",
    "    deriv_theta0 = 2/N*sum(theta1*x + theta0 - y)\n",
    "    deriv_theta1 = 2/N*sum(x*(theta1*x + theta0 - y))\n",
    "    # put in vector form\n",
    "    gradient = np.array([deriv_theta0, deriv_theta1])\n",
    "    return gradient\n",
    "\n",
    "#------------------------\n",
    "# Create variables\n",
    "#------------------------\n",
    "\n",
    "# Data to import into functions\n",
    "x = df['age'].values\n",
    "y = df['height'].values\n",
    "\n",
    "# Starting point\n",
    "theta0 = 0\n",
    "theta1 = 0\n",
    "\n",
    "# Step size to move along gradient\n",
    "gamma = 0.01\n",
    "\n",
    "# Starting values of theta vector\n",
    "Theta = np.array([theta0,theta1])\n",
    "\n",
    "# initialize num of steps to take\n",
    "totalNumSteps = 0\n",
    "# create a max number of steps to take\n",
    "maxSteps = 5000\n",
    "# how close we want to be to f\n",
    "tolerance = 0.000001\n",
    "# initial difference between old and new theta values\n",
    "diff = 100\n",
    "\n",
    "#------------------------\n",
    "# Initialize lists\n",
    "#------------------------\n",
    "\n",
    "# creates list of all theta pairs\n",
    "thetaValuesList = [Theta]\n",
    "# creates list of all distance function values\n",
    "fValuesList = [f(x,y,Theta)]\n",
    "# creates list of the norm between old and new theta values\n",
    "diffList = [diff]\n",
    "\n",
    "#------------------------\n",
    "# Gradient descent calcs\n",
    "#------------------------\n",
    "\n",
    "while((totalNumSteps < maxSteps)&(diff > tolerance)):\n",
    "\n",
    "    # Calculate new (x,y) values - move along gradient to new (x,y) position\n",
    "    newTheta = Theta - gamma*gradf(x,y,Theta)\n",
    "    # Add to list of (x,y) values\n",
    "    thetaValuesList.append(newTheta)\n",
    "\n",
    "    # Calculate the difference between current and new (x,y) values\n",
    "    diff = norm(newTheta-Theta,2)\n",
    "    diffList.append(diff)\n",
    "\n",
    "    # Reassign current (x,y) to new (x,y)\n",
    "    Theta = newTheta\n",
    "    # Add to list of f function values\n",
    "    fValuesList.append(f(x,y,Theta))\n",
    "\n",
    "    # Add 1 to counter for total number of steps\n",
    "    totalNumSteps += 1\n",
    "\n",
    "\n",
    "print('Our theta_0 value after', totalNumSteps, 'time steps is', thetaValuesList[-1][0])\n",
    "print('Our theta_1 value after', totalNumSteps, 'time steps is',  thetaValuesList[-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eca94ae",
   "metadata": {
    "id": "7eca94ae"
   },
   "source": [
    "### Part 3\n",
    "\n",
    "When you have found $\\boldsymbol{\\theta}$, plot the straight line fit from your algorithm on the same graph as your training data.\n",
    "\n",
    "Note that for most machine learning problems, $x$ is very high dimensional, so we may not be able to plot the prediction.  However, in this example, we have only one feature (age).  Being able to plot this gives a nice sanity-check on our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f77fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "executionInfo": {
     "elapsed": 3526,
     "status": "ok",
     "timestamp": 1696391659078,
     "user": {
      "displayName": "Christina Edholm",
      "userId": "06638694382813985364"
     },
     "user_tz": 420
    },
    "id": "dd6f77fa",
    "outputId": "f6d917f7-795e-4e74-cc1c-d612252ccb5b"
   },
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Compute function to plot\n",
    "#------------------------\n",
    "\n",
    "# Get our theta values from above\n",
    "theta0, theta1 = thetaValuesList[-1]\n",
    "\n",
    "# Create a line with those values\n",
    "predHeight = theta1 * x + theta0\n",
    "\n",
    "#------------------------\n",
    "# Create plot\n",
    "#------------------------\n",
    "\n",
    "# Make figure size\n",
    "fig = plt.figure(dpi = 140)\\\n",
    "\n",
    "# Plot data\n",
    "#------------------------\n",
    "\n",
    "# Plot df data\n",
    "df.plot(x = 'age', y = 'height', kind = 'scatter', color = 'crimson', s = 20, label = 'data', ax = plt.gca())\n",
    "\n",
    "# Plot line we found\n",
    "plt.plot(x, predHeight, marker = '', color = 'steelblue', label = 'predicted', lw = 2)\n",
    "\n",
    "# Label figure\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('Height (centimeters)')\n",
    "plt.title('Actual vs. Predicted')\n",
    "\n",
    "# Add legend\n",
    "#------------------------\n",
    "plt.legend()\n",
    "\n",
    "# Uncommment to save figure\n",
    "#------------------------\n",
    "plt.savefig('actualVsPredicted.pdf', bbox_inches='tight', dpi= 300)\n",
    "\n",
    "# Show the plot\n",
    "#------------------------\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c7854",
   "metadata": {
    "id": "ac0c7854"
   },
   "source": [
    "### Part 4\n",
    "\n",
    "Finally, we'd like to make some predictions using the learned hypothesis. We will use the model to predict the height for a two boys of age 3.5 and age 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d2cb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1696391662619,
     "user": {
      "displayName": "Christina Edholm",
      "userId": "06638694382813985364"
     },
     "user_tz": 420
    },
    "id": "492d2cb1",
    "outputId": "aefea041-7e1e-4913-f0f0-3ee8f486964c"
   },
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Predict height funtion\n",
    "#------------------------\n",
    "def predictedHeight(age, Theta):\n",
    "    theta0, theta1 = Theta\n",
    "    predictedHeight = theta1 * age + theta0\n",
    "    return predictedHeight\n",
    "\n",
    "# Find predictions\n",
    "#------------------------\n",
    "\n",
    "# Age 3.5\n",
    "age = 3.5\n",
    "print('A boy of age', age,'has predicted height %.3f' %predictedHeight(age, thetaValuesList[-1]), 'centimeters.')\n",
    "\n",
    "# Age 7\n",
    "age = 7\n",
    "print('A boy of age', age,'has predicted height %.3f' %predictedHeight(age, thetaValuesList[-1]), 'centimeters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098df2f9",
   "metadata": {
    "id": "098df2f9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
