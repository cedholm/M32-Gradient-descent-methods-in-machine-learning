{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c312c65",
   "metadata": {
    "id": "40aaf12a"
   },
   "source": [
    "# Gradient Descent with Logistic Regression - Example Default Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e74cb9",
   "metadata": {
    "id": "7223c7b8"
   },
   "source": [
    "## Predicting default on loans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d075e9",
   "metadata": {
    "id": "2343eb87"
   },
   "source": [
    "Suppose we want to predict whether someone will default on their loan based on their income and the amount that they borrowed.\n",
    "\n",
    "We will look at the dataset Default-Data which has three columns:  the first column is the loan amount, the second column is income, and the third column is the status of the loan.  \n",
    "\n",
    "If the borrower has defaulted on their loan, we mark their status with a 1 in that column.  If the borrower has not defaulted on their loan, we mark their status as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dacbd6",
   "metadata": {
    "id": "3932b110"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a8930",
   "metadata": {
    "id": "df74f57f",
    "outputId": "5297812c-fbd1-4632-e0e8-3f4e96d4ca6c"
   },
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Import packages\n",
    "#------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Plot style\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "#------------------------\n",
    "# Make dataframe\n",
    "#------------------------\n",
    "\n",
    "# Creates a dataframe from file called Default-Data.csv\n",
    "#---------------------\n",
    "url = 'https://raw.githubusercontent.com/cedholm/M32-Gradient-descent-methods-in-machine-learning/main/Default-Data.csv'\n",
    "dfLoans = pd.read_csv(url)\n",
    "\n",
    "# Print some info about the dataset\n",
    "#---------------------\n",
    "\n",
    "# Prints first 5 lines of data\n",
    "print('The first 5 lines of data look like:\\n', dfLoans.head(5))\n",
    "\n",
    "# Print basic stats on data\n",
    "print('Some basic stats on our data are:\\n', dfLoans.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6ad8e6",
   "metadata": {
    "id": "71c534b1"
   },
   "source": [
    "## Create plots\n",
    "Let us plot our data with the x-axis displaying the borrower's loan amount, the y-axis the borrower's income, and the color of the data representing the borrower's status.  Recall that 0 means the borrower has not defaulted on their loan and 1 means that they have defaulted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f107ca01",
   "metadata": {
    "id": "4e2cf1b5",
    "outputId": "789b2002-f0cc-4360-d537-a916c461a4eb"
   },
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Create plot\n",
    "#------------------------\n",
    "\n",
    "# Make figure size\n",
    "fig = plt.figure(dpi = 140)\n",
    "\n",
    "# Plot df data\n",
    "#---------------------\n",
    "sns.scatterplot(data = dfLoans, x='loan_amount', y='income', hue='status', style = 'status')\n",
    "\n",
    "# Label figure\n",
    "plt.xlabel('Loan Amount (dollars)')\n",
    "plt.ylabel('Income')\n",
    "plt.title('Loan Status by Loan Amount and Income')\n",
    "\n",
    "# Uncommment to save figure\n",
    "#---------------------\n",
    "plt.savefig('loanStatus.pdf', bbox_inches='tight', dpi= 300)\n",
    "\n",
    "# Show the plot\n",
    "#---------------------\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc62e7",
   "metadata": {
    "id": "53fe04c2"
   },
   "source": [
    "## Add logistic and linear regression models\n",
    "We can use both logistic and linear regression here to see how they differ along with plotting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e90b1",
   "metadata": {
    "id": "120ed090"
   },
   "source": [
    "### Normalizing data\n",
    "\n",
    "In order to get the algorithm to converge, it is helpful to rescale the data so that they are all more or less the same size.  We can do this by subtracting the mean of each input category (loan amount and income), and dividing by the standard deviation of that category.  The values of the estimated coefficients, $\\theta_i$, must then also be rescaled to match the original unscaled variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd1feac",
   "metadata": {
    "id": "dbe8582a"
   },
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Create normalized data and label variables\n",
    "#------------------------\n",
    "\n",
    "# Name the data\n",
    "#------------------------\n",
    "x1 = dfLoans['loan_amount'].values\n",
    "x2 = dfLoans['income'].values\n",
    "\n",
    "# Normalize data and relabel\n",
    "#------------------------\n",
    "normalized_x1 = (x1-np.mean(x1))/np.std(x1)\n",
    "normalized_x2 = (x2-np.mean(x2))/np.std(x2)\n",
    "\n",
    "# Data to import into functions\n",
    "#------------------------\n",
    "X = np.column_stack((normalized_x1,normalized_x2)) # our normalized x_1 and x_2 data in matrix form X=[x_1 x_2]\n",
    "y = dfLoans['status'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19285f5",
   "metadata": {
    "id": "8efeba52"
   },
   "source": [
    "### Logisitic regression model\n",
    "\n",
    "We want to maximize the log likelihood function, so the cost function that we want to *minimize* is the negative of the log likelihood.\n",
    "\n",
    "The update rule is\n",
    "$$\n",
    "\\boldsymbol{\\theta}^{(t+1)}=\\boldsymbol{\\theta}^{(t)}-\\gamma^{(t)}  \\nabla (- \\ell) =\\boldsymbol{\\theta}^{(t)}+\\gamma^{(t)}  \\nabla \\ell\n",
    "$$\n",
    "\n",
    "Note that, in the code, we are writing $\\boldsymbol{\\theta}$, the gradient vector $\\nabla \\ell$, and the input vector ${\\bf x}^{(i)}$, as *column* vectors.\n",
    "\n",
    "We note that since $\\nabla \\ell$ involves a sum, a large data set could result in large values of the partial derivatives.  To control the size of these entries, it is often helpful to use the *mean* log likelihood, ie. $\\frac{1}{N} \\nabla \\ell$. This is what we recommend for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67292c4",
   "metadata": {
    "id": "befe6bc1"
   },
   "source": [
    "Now, we start our logistic regression with the normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a397f2d",
   "metadata": {
    "id": "3f5a9635",
    "outputId": "562ed4e3-e433-485f-b3f7-70372afd1535"
   },
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Create greadient function\n",
    "#------------------------\n",
    "\n",
    "# Create the gradient vector\n",
    "#------------------------\n",
    "def gradf(X,y, Theta):\n",
    "\n",
    "    # Create Xtilde = column of ones merged with X\n",
    "    N = len(y)\n",
    "    X0 = np.ones((N,1))\n",
    "    # Add column of ones to create matrix Xtilde\n",
    "    Xtilde = np.column_stack((X0, X))\n",
    "\n",
    "    # Compute scores via dot product\n",
    "    scores = Xtilde@Theta # Nx1 vector\n",
    "\n",
    "    # Compute probability function\n",
    "    predictions = 1 / (1 + np.exp(-scores)) # Nx1\n",
    "\n",
    "    # Compute gradient via dot product\n",
    "    gradient = (y-predictions)@Xtilde # 1x3\n",
    "    return gradient\n",
    "\n",
    "#------------------------\n",
    "# Parameters\n",
    "#------------------------\n",
    "N = len(y)\n",
    "\n",
    "# Starting point\n",
    "Theta = [0,0,0]\n",
    "\n",
    "# Step size to move along gradient\n",
    "gamma = 0.01\n",
    "\n",
    "# initialize num of steps to take\n",
    "totalNumSteps = 0\n",
    "# create a max number of steps to take\n",
    "maxSteps = 200000\n",
    "# how close we want to be to f\n",
    "tolerance = 0.000001\n",
    "# initial difference between old and new theta values\n",
    "diff = 100\n",
    "\n",
    "#------------------------\n",
    "# Gradient descent calcs\n",
    "#------------------------\n",
    "\n",
    "while((totalNumSteps < maxSteps)&(diff > tolerance)):\n",
    "\n",
    "    # Calculate new (x,y) values - move along gradient to new (x,y) position\n",
    "    newTheta = Theta + 1/N*gamma*gradf(X,y,Theta)\n",
    "\n",
    "    # Calculate the difference between current and new (x,y) values\n",
    "    diff = norm(newTheta-Theta,2)\n",
    "\n",
    "    # Reassign current (x,y) to new (x,y)\n",
    "    Theta = newTheta\n",
    "\n",
    "    # Add 1 to counter for total number of steps\n",
    "    totalNumSteps += 1\n",
    "\n",
    "# Get thetas\n",
    "#------------------------\n",
    "scaled_theta0 = Theta[0]\n",
    "scaled_theta1 = Theta[1]\n",
    "scaled_theta2 = Theta[2]\n",
    "\n",
    "# Calculuate unscaled thetas\n",
    "#------------------------\n",
    "theta0 = scaled_theta0 - scaled_theta1*np.mean(x1)/(np.std(x1)) - scaled_theta2*np.mean(x2)/(np.std(x2))\n",
    "theta1 = scaled_theta1/(np.std(x1))\n",
    "theta2 = scaled_theta2/(np.std(x2))\n",
    "\n",
    "print('After', totalNumSteps,'timesteps, the thetas for our logistic regression model are:\\ntheta0 =', theta0)\n",
    "print('theta1 =', theta1)\n",
    "print('theta2 =', theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd4b041",
   "metadata": {
    "id": "8e2a8661"
   },
   "source": [
    "### Linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1fea0",
   "metadata": {
    "id": "01365173",
    "outputId": "6bf5a469-34b3-406b-8f9b-4dfc818bc15d"
   },
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Create normalized data and label variables\n",
    "#------------------------\n",
    "\n",
    "# Name the data\n",
    "#------------------------\n",
    "x1 = dfLoans['loan_amount'].values\n",
    "x2 = dfLoans['income'].values\n",
    "y = dfLoans['status'].values\n",
    "\n",
    "# Normalize data and relabel\n",
    "#------------------------\n",
    "normalized_x1 = (x1-np.mean(x1))/np.std(x1)\n",
    "normalized_x2 = (x2-np.mean(x2))/np.std(x2)\n",
    "\n",
    "# Data to import into functions\n",
    "#------------------------\n",
    "X = np.column_stack((normalized_x1,normalized_x2))\n",
    "\n",
    "\n",
    "#------------------------\n",
    "# Create gradient function\n",
    "#------------------------\n",
    "\n",
    "# Create the gradient vector\n",
    "# Here, we have \\nabla D = 2\\sum_{k=1}^N (\\theta_1 x_k + \\theta_0 - y_k)*<1, x_k>\n",
    "def gradf(X, y, Theta):\n",
    "    x1 = X[:,0]\n",
    "    x2 = X[:,1]\n",
    "    # divide up thetas\n",
    "    theta0, theta1, theta2 = Theta\n",
    "    N = len(y)\n",
    "    # find derivatives w.r.t each theta\n",
    "    deriv_theta0 = 2/N*sum(theta2*x2 + theta1*x1 + theta0 - y)\n",
    "    deriv_theta1 = 2/N*sum(x1*(theta2*x2 + theta1*x1 + theta0 - y))\n",
    "    deriv_theta2 = 2/N*sum(x2*(theta2*x2 + theta1*x1 + theta0 - y))\n",
    "    # put in vector form\n",
    "    gradient = np.array([deriv_theta0, deriv_theta1, deriv_theta2])\n",
    "    return gradient\n",
    "\n",
    "#------------------------\n",
    "# Parameters\n",
    "#------------------------\n",
    "\n",
    "# Starting point\n",
    "linTheta = np.array([0,0,0])\n",
    "\n",
    "# Step size to move along gradient\n",
    "gamma = 0.01\n",
    "\n",
    "# initialize num of steps to take\n",
    "totalNumSteps = 0\n",
    "# create a max number of steps to take\n",
    "maxSteps = 10000\n",
    "# how close we want to be to f\n",
    "tolerance = 0.000001\n",
    "# initial difference between old and new theta values\n",
    "diff = 100\n",
    "\n",
    "#------------------------\n",
    "# Gradient descent calcs\n",
    "#------------------------\n",
    "\n",
    "while((totalNumSteps < maxSteps)&(diff > tolerance)):\n",
    "\n",
    "    # Calculate new (x,y) values - move along gradient to new (x,y) position\n",
    "    newLinTheta = linTheta - gamma*gradf(X, y, linTheta)\n",
    "\n",
    "    # Calculate the difference between current and new (x,y) values\n",
    "    diff = norm(newLinTheta-linTheta,2)\n",
    "\n",
    "    # Reassign current (x,y) to new (x,y)\n",
    "    linTheta = newLinTheta\n",
    "\n",
    "    # Add 1 to counter for total number of steps\n",
    "    totalNumSteps += 1\n",
    "\n",
    "# Get thetas\n",
    "#------------------------\n",
    "scaled_lintheta0 = linTheta[0]\n",
    "scaled_lintheta1 = linTheta[1]\n",
    "scaled_lintheta2 = linTheta[2]\n",
    "\n",
    "# Calculuate unscaled thetas\n",
    "#------------------------\n",
    "lintheta0 = scaled_lintheta0 - scaled_lintheta1*np.mean(x1)/(np.std(x1)) - scaled_lintheta2*np.mean(x2)/(np.std(x2))\n",
    "lintheta1 = scaled_lintheta1/(np.std(x1))\n",
    "lintheta2 = scaled_lintheta2/(np.std(x2))\n",
    "\n",
    "print('After', totalNumSteps,'timesteps, the thetas for our linear regression model are:\\ntheta0 =', lintheta0)\n",
    "print('theta1 =', lintheta1)\n",
    "print('theta2 =', lintheta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5709ec22",
   "metadata": {
    "id": "d5d52933"
   },
   "source": [
    "Now, we have our two models: the logistic model and the linear model to compare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6febfede",
   "metadata": {
    "id": "53f99edb"
   },
   "source": [
    "We can plot our new functions if we'd like.  We start by creating some values for loan amounts ($x_1$) and incomes ($x_2$).  Then, we create our log-likelihood function using our new thetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eeb517",
   "metadata": {
    "id": "3332dd6d"
   },
   "outputs": [],
   "source": [
    "# Pick the number of points to plot\n",
    "#---------------------\n",
    "n = 200\n",
    "\n",
    "# Values to plot for our function\n",
    "#---------------------\n",
    "x1 = np.linspace(min(dfLoans['loan_amount']), max(dfLoans['loan_amount']), n)\n",
    "x2 = np.linspace(min(dfLoans['income']), max(dfLoans['income']), n)\n",
    "\n",
    "# Plug our values into our function log-likelihood function\n",
    "# 1/(1+exp(-(theta0 + theta1*loanAmount = theta2*income)))\n",
    "#---------------------\n",
    "logModelPlot = lambda x1, x2: 1/(1+np.exp(-theta0 -theta1*x1 - theta2*x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7fdd3c",
   "metadata": {
    "id": "91ceac6a"
   },
   "source": [
    "We can setup to do the same for our linear model to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e85409",
   "metadata": {
    "id": "8889c2cd"
   },
   "outputs": [],
   "source": [
    "# Plug our values into our function linear function\n",
    "# 1/(1+exp(-(theta0 + theta1*loanAmount = theta2*income)))\n",
    "#---------------------\n",
    "linModelPlot = lambda x1, x2: lintheta0 + lintheta1*x1 + lintheta2*x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88849706",
   "metadata": {
    "id": "af3e7dd2"
   },
   "source": [
    "### Plot data with our models\n",
    "Now, we will plot our data and our two regression lines: 1) logistic regression, 2) linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760e354",
   "metadata": {
    "id": "984587ba",
    "outputId": "5561d52a-5eaf-49ae-9479-4dc1a7d4f6cf"
   },
   "outputs": [],
   "source": [
    "#-----------------------------\n",
    "# Plot our data and functions\n",
    "#-----------------------------\n",
    "\n",
    "# Make figure size\n",
    "#---------------------\n",
    "fig = plt.figure(dpi = 140)\n",
    "\n",
    "# Plot data\n",
    "#---------------------\n",
    "sns.scatterplot(data = dfLoans, x = 'loan_amount', y = 'status', color='crimson', label = 'Data')\n",
    "# Plot log model\n",
    "plt.plot(x1, logModelPlot(x1,x2), '-', color = 'steelblue', linewidth = 2, label = 'Logistic Model')\n",
    "# Plot linear model\n",
    "plt.plot(x1, linModelPlot(x1,x2), '-', color = 'purple', linewidth = 2, label = 'Linear Model')\n",
    "\n",
    "# Label axes + title\n",
    "#---------------------\n",
    "plt.xlabel('Loan Amount (dollars)')\n",
    "plt.ylabel('Status')\n",
    "plt.title('Loan Status')\n",
    "plt.ylim(-0.1,1.1)\n",
    "\n",
    "# Add legend\n",
    "#---------------------\n",
    "plt.legend()\n",
    "\n",
    "# Uncommment to save figure\n",
    "#---------------------\n",
    "plt.savefig('loanStatusLogLinCompare.pdf', bbox_inches='tight', dpi= 300)\n",
    "\n",
    "# Show the plot\n",
    "#---------------------\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffef98d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
